library(caret)
intrain<-createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
training<-segmentationOriginal[intrain, ]
testing<-segmentationOriginal[-intrain, ]
set.seed(125)
cartmodel<-train(training$Class~., method="rpart", data=training)
cartmodel<-train(Class~., method="rpart", data=training)
cartmodel$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
install.packages(rattle)
install.packages("rattle")
rattle::fanRpartPlot(cartmodel$finalModel)
fanRpartPlot(cartmodel$finalModel)
fancyRpartPlot(cartmodel$finalModel)
cartmodel<-train(Class~., method="rpart", data=training)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(cartmodel$finalModel)
library(rpart)
fancyRpartPlot(cartmodel$finalModel)
library(rpart)
fancyRpartPlot(cartmodel$finalModel)
fancyRpartPlot(cartmodel$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
intrain<-createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
training<-segmentationOriginal[intrain, ]
testing<-segmentationOriginal[-intrain, ]
set.seed(125)
cartmodel<-train(Class~., method="rpart", data=training)
suppressMessages(library(rattle))
library(rpart)
fancyRpartPlot(cartmodel$finalModel)
install.packages("rpart.plot")
install.packages("rpart.plot")
install.packages("rpart.plot")
fancyRpartPlot(cartmodel$finalModel)
predict(cartmodel, newdata = testing)
cartmodel$finalModel
library(pgmm)
data(olive)
olive=olive[,-1]
newdata<-as.data.frame(t(colMeans(olive)))
olivemodel<-train(Area, method="rpart", data=olive)
olivemodel<-train(Area~., method="rpart", data=olive)
predict(olivemodel, newdata = newdata)
olive$Area
dim(olive$Area)
str(olive)
plot(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# Then set the seed to 13234 and fit a logistic regression model (method="glm", be sure to specify family="binomial") with Coronary Heart Disease (chd) as the outcome and age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol as predictors. Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
# What is the misclassification rate on the training set? What is the misclassification rate on the test set?
set.seed(13234)
fit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
method='glm', family=binomial, data=trainSA)
library(ElemStatLearn)
data(SAheart)
set.seed(13234)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(13234)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# Then set the seed to 13234 and fit a logistic regression model (method="glm", be sure to specify family="binomial") with Coronary Heart Disease (chd) as the outcome and age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol as predictors. Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
# What is the misclassification rate on the training set? What is the misclassification rate on the test set?
set.seed(13234)
fit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
method='glm', family=binomial, data=trainSA)
lapply(list(testSA, trainSA), function(set) {missClass(set$chd, predict(fit, set))} )
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
fit <- train(y ~ .,  data=vowel.train, method='rf')
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
# Accuracy among the test set samples where the two methods agree
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
install.packages("shiny")
library(shiny)
install.packages(leaflet)
install.packages("leaflet")
urltrain<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urltest<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urltrain, destfile = "pml-training.csv", method = "curl")
download.file(urltest, destfile = "pml-testing.csv", method = "curl")
urltrain<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urltest<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url=urltrain, destfile = "pml-training.csv", method = "curl")
download.file(url=urltest, destfile = "pml-testing.csv", method = "curl")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv", method = "curl")
urltrain<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urltest<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url=urltrain, destfile = "pml-training.csv", method = "internal")
download.file(url=urltrain, destfile = "pml-training.csv")
download.file(url=urltest, destfile = "pml-testing.csv")
if (!file.exists(pml-training.csv)){
download.file(url=urltrain, destfile = "pml-training.csv")
}
if (!file.exists("pml-training.csv")){
download.file(url=urltrain, destfile = "pml-training.csv")
}
if (!file.exists("pml-testing.csv")){
download.file(url=urltest, destfile = "pml-testing.csv")
}
if (!file.exists("pml-testing.csv")){
download.file(url=urltest, destfile = "pml-testing.csv")
}
dftraining<-read.csv("pml-training.csv")
dftest<-read.csv("pml-testing.csv")
dftest
dftraining
head(dftraining)
library(caret)
set.seed(400)
inTrain = createDataPartition(dftraining$Classe, p = .60)[[1]]
str(dftraining)
features <- names(dttesting[,colSums(is.na(dttesting)) == 0])[8:59]
# Only use features used in testing cases.
dttraining <- dttraining[,c(features,"classe")]
dttesting <- dttesting[,c(features,"problem_id")]
dim(dttraining); dim(dttesting);
features <- names(dftesting[,colSums(is.na(dftesting)) == 0])[8:59]
# Only use features used in testing cases.
dftraining <- dftraining[,c(features,"classe")]
dftesting <- dftesting[,c(features,"problem_id")]
dim(dftraining)
dim(dftesting)
The two are downloaded directly to the directory where the .Rmd file is located. Two datasets are created with the read.csv() function.
```{r, echo=FALSE}
urltrain<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urltest<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# Download the training dataset if not already downloaded
if (!file.exists("pml-training.csv")){
download.file(url=urltrain, destfile = "pml-training.csv")
}
# Download the test dataset if not already downloaded
if (!file.exists("pml-testing.csv")){
download.file(url=urltest, destfile = "pml-testing.csv")
}
# Read the two data files.
dftraining<-read.csv("pml-training.csv")
dftesting<-read.csv("pml-testing.csv")
features <- names(dftesting[,colSums(is.na(dftesting)) == 0])[8:59]
# Only use features used in testing cases.
dftraining <- dftraining[,c(features,"classe")]
dftesting <- dftesting[,c(features,"problem_id")]
dim(dftraining)
dim(dftesting)
dim(dftraining)
dim(dftesting)
modelFit <- rpart(classe ~ ., data = training, method="class")
fancyRpartPlot(modelFit)
# Create subsets on the training dataset.
training <- dftraining[inTrain,]
testing <- dftraining[-inTrain,]
prediction <- predict(modelFit, testing, type = "class")
confusionMatrix(prediction, predict(modelFit, testing))
modelFit <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
library(randomForest)
modelFit <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
inTrain <- createDataPartition(y=dftraining$classe, p=0.6, list=FALSE)
# Create subsets on the training dataset.
training <- dftraining[inTrain,]
testing <- dftraining[-inTrain,]
dim(training)
dim(testing)
modelFit <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
qplot(training,prediction,data=testing)
str(dftraining)
hist(training)
modelFit <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
set.seed(54321)
vtraining <- predict(modelFit, training)
print(confusionMatrix(vtraining, training$classe))
validation <- predict(modelFit, testing)
print(confusionMatrix(validation, testing$classe))
prediction <- predict(modelFit, dftesting)
prediction
plot(training$classe)
qplot(training$classe)
plot(testing$classe)
qplot(modelFit$classes)
qplot(modelFit$classes, modelFit$predicted)
prediction <- predict(modelFit, dftesting)
prediction
folds<-createFolds(y=training$classe, k=20, list=TRUE, returnTrain = TRUE)
folds
folds<-createFolds(y=testing$classe, k=20, list=TRUE, returnTrain = TRUE)
folds
folds<-createFolds(y=testing$classe, k=10, list=TRUE, returnTrain = TRUE)
folds
prediction <- predict(modelFit, dftesting)
prediction
filename = paste0("idproblem", i, ".txt")
print(prediction)
head(training)
str(training)
lm1 <- lm(class ~ .,data=training)
summary(lm1)
lm1 <- lm(classe ~ .,data=training)
summary(lm1)
lm1 <- lm(training$classe ~ .,data=training)
summary(lm1)
lm1 <- lm(training$classe ~ ., data=training)
training$classe<-factor(training$classe)
lm1 <- lm(training$classe ~ ., data=training)
plot(training$classe, pch=19)
install.packages("leaflet")
df<-read.csv("universities.csv")
df
table(df)
head(df)
df<-leaflet()%>%
addTiles()%>%
addMarkers()
leafletMap<-leaflet()%>%
addTiles()
leafletMap
leafletMap<-leaflet()%>%
addTiles()
library(dplyr)
leafletMap<-leaflet()%>%
addTiles()
leafletMap
df<-leaflet() %>%
addTiles() %>%
addMarkers()
library(leaflet)
df<-read.csv("universities.csv")
head(df)
df<-leaflet() %>%
addTiles() %>%
addMarkers()
df<-data.frame(lat=df$Lat, lng=df$Lon)
df<-leaflet() %>%
addTiles() %>%
addMarkers()
df<-read.csv("universities.csv")
head(df)
df<-data.frame(name=df$University, lat=df$Lat, lng=df$Lon)
df
df<-leaflet() %>%
addTiles() %>%
addMarkers()
df<-data.frame(data=df, name=df$University, lat=df$Lat, lng=df$Lon)
name<-df$name
name
df<-read.csv("universities.csv")
head(df)
leafletMap<-leaflet(df)%>%
addTiles()
leafletMap
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers()
set.seed(2016-12-04)
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers()
leafletMap
df<-read.csv("universities.csv")
df
capetownIcon<-makeIcon(iconUrl = "https://github.com/ysebega/RMarkdownLeaflet/blob/master/1UCT.png", iconWidth = 31*215/230, iconHeight = 31, iconAnchorX = 31*215/230/2, iconAnchorY = 16)
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers(icon=capetownIcon)
leafletMap
capetownIcon<-makeIcon(iconUrl = "https://github.com/ysebega/RMarkdownLeaflet/blob/master/1UCT.png", iconWidth = 31*215/230, iconHeight = 31, iconAnchorX = 31*215/230/2, iconAnchorY = 16)
capetownIcon
capetownIcon<-makeIcon(iconUrl = "1UCT.png" , iconWidth = 31*215/230, iconHeight = 31, iconAnchorX = 31*215/230/2, iconAnchorY = 16)
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers(icon=capetownIcon)
leafletMap
icons<-makeIcon(c("1UCT.png", "2WITS.png", "3STELL.png", "4PTA.png", "5WC.png", "6KZN.png", "7RHODES.png", "8FS.png", "9JHB.png", "10PENIN.png"))
icons<-makeIcon(iconUrl=c("1UCT.png", "2WITS.png", "3STELL.png", "4PTA.png", "5WC.png", "6KZN.png", "7RHODES.png", "8FS.png", "9JHB.png", "10PENIN.png"))
icons<-makeIcon(iconUrl=c("1UCT.png", "2WITS.png", "3STELL.png", "4PTA.png", "5WC.png", "6KZN.png", "7RHODES.png", "8FS.png", "9JHB.png", "10PENIN.png"), iconWidth = 31*215/230, iconHeight = 31, iconAnchorX = 31*215/230/2, iconAnchorY = 16)
set.seed(2016-12-04)
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers(icon=icons)
leafletMap
iconsUniversities<-makeIcon(iconUrl=c("1UCT.png", "2WITS.png", "3STELL.png", "4PTA.png", "5WC.png", "6KZN.png", "7RHODES.png", "8FS.png", "9JHB.png", "10PENIN.png"))
set.seed(2016-12-04)
leafletMap<-leaflet(df) %>%
addTiles() %>%
addMarkers(icon=iconsUniversities)
leafletMap
install.packages('rsconnect')
rsconnect::setAccountInfo(name='ysebega',
token='09C8D8D4C4E517F59E7FF2537CD4FEC4',
secret='<SECRET>')
rsconnect::setAccountInfo(name='ysebega',
token='09C8D8D4C4E517F59E7FF2537CD4FEC4',
secret='+MaJbHcwykP+5QOC3CBnRr1FplNNV0J+45g2JNmV')
library(rsconnect)
rsconnect::deployApp('C:\Users\DataScience\Documents')
rsconnect::deployApp('C:\\Users\\DataScience\\Documents')
rsconnect::deployApp('C:\\Users\\DataScience\\Documents\\leaflet')
q()
install.packages(plotly)
install.packages("plotly")
dataset(presidents)
data(presidents)
presidents
data("discoveries")
df<-discoveries
data("discoveries")
df<-discoveries
df
plot(df)
plot(df, xlab="Date", ylab="Discovery Frequency")
?plot
plot(df, xlab="Date", ylab="Discovery Frequency", main="Discoveries")
plot(df, xlab="Date", ylab="Discovery Frequency", main="Inventions & Discoveries from 1860-1959")
library(plotly)
str(discoveries)
plot_ly(discoveries)
library(plotly)
plot_ly(discoveries)
library(plotly)
install.packages("plotly")
library(plotly)
library(ggplot2)
library(plotly)
library(ggplot2)
library(plotly)
library(ggplot2)
library(plotly)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(plotly)
install.packages("ggplot2")
library(ggplot2)
library(plotly)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(plotly)
plot_ly(discoveries)
df<-data.frame(discoveries)
plot_ly(df)
str(mtcars)
str(df)
plot_ly(df, x=discoveries)
plot_ly(df, x=discoveries, mode="markers")
summarise(df)
str(df)
str(infert)
data("infert")
df<-data.frame(infert)
library(ggplot2)
library(plotly)
plot_ly(df, x=education, y=age, mode="markers")
plot_ly(infert, x=education, y=age, mode="markers")
data("infert")
plot_ly(infert, x=education, y=age, mode="markers")
plot_ly(df, x=discoveries)
plot(df, xlab="Date", ylab="Discovery Frequency", main="Inventions & Discoveries from 1860-1959")
df
data("discoveries")
df<-data.frame(discoveries)
df
str(df)
plot_ly(df, x=df$discoveries)
?plot_ly
df<-scan(discoveries)
df<-scan("discoveries")
dfs<-ts(df)
dfs
dfs<-ts(df, frequency = 1, start = c(1860, 1))
plot_ly(dfs )
str(cars)
data("cars")
df<-data.frame(cars)
```{r discoveries, echo=FALSE}
library(ggplot2)
library(plotly)
plot_ly(df, x=speed, y=dist)
data("discoveries")
df<-data.frame(discoveries)
plot_ly(x=discoveries, type="histogram")
plot_ly(x=discoveries, type="histogram", xlab("Date"))
plot_ly(data=df, x=discoveries, type="histogram", xlab("Date"))
plot_ly(x=discoveries, type="histogram")
plot_ly(x=discoveries, type="histogram", xlab("Test"))
plot_ly(x=discoveries, type="histogram", xlab="Date")
plot_ly(x=discoveries, type="histogram")
library(ggplot2)
library(plotly)
library(plotly)
plot_ly(x=discoveries, type="histogram")
data("JohnsonJohnson")
df<-data.frame(JohnsonJohnson)
df
str(df)
data("longley")
df<-data.frame(longley)
str(df)
data("longley")
df<-data.frame(longley)
plot_ly(x=df$Unemployed, y=df$Year, mode="markers")
dt<-data("discoveries")
df<-data.frame(dt)
dt<-data("discoveries")
df<-data.frame(dt)
plotly(x=time(discoveries), y=discoveries)
plot_ly(x=df$Year, y=df$Unemployed)
plot_ly(x=df$Year, y=df$Unemployed, mode="markers")
library(ggplot2)
library(plotly)
plot_ly(x=df$Year, y=df$Unemployed, mode="markers")
data("longley")
df<-data.frame(longley)
library(ggplot2)
library(plotly)
plot_ly(x=df$Year, y=df$Unemployed, mode="markers")
library(plotly)
plot_ly(x=df$Year, y=df$Unemployed, mode="markers", size = df$Population)
```{r discoveries, echo=FALSE, warning=FALSE}
shiny::runApp('shiny/myApp')
runApp('shiny/myApp')
runApp('shiny/myApp')
